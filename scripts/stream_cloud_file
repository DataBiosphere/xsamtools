#!/usr/bin/env python
import sys
import argparse

from terra_notebook_utils import gs
import gs_chunked_io as gscio
"""
This streams a cloud key directly to stdout.  This allows:
  1. The stream to be modified/sliced along the way.
  2. Data to be piped with conventional bash pipes:
      e.g., python stream_cloud_file.py | some_tool > output.txt

TODO: This might be able to be replaced with "gsutil cat" if it ever allows multiple slices.
      Currently one slice is implemented, for example: "gsutil cat -r 0-99 gs://lons-test/ce#5b.cram"
      which would print the first 100 bytes.
"""


def main(argv=sys.argv[1:]):
    parser = argparse.ArgumentParser(description='Streams out a provided gs:// file path.',
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('--path', type=str, required=True, help='A google path to stream.')
    parser.add_argument('--buffer', type=int, default=16384, help='Size of the buffer used to stream a single file.')
    o = parser.parse_args(argv)

    assert o.path.startswith('gs://'), 'Please pass in a google bucket path.  ' \
                                       'e.g. "gs://example/key/to/file.txt"'
    gs_path = o.path.strip()[len('gs://'):].split('/', 1)
    assert len(gs_path) == 2, 'Please specify a key in addition to the bucket path.  ' \
                              'e.g. "gs://example/key/to/file.txt"'

    bucket = gs.get_client().get_bucket(gs_path[0])
    blob = bucket.get_blob(gs_path[1])

    with gscio.Reader(blob) as fh:
        portion = fh.read(o.buffer)
        sys.stdout.buffer.write(portion)
        while portion:
            portion = fh.read(o.buffer)
            sys.stdout.buffer.write(portion)


if __name__ == '__main__':
    main()
